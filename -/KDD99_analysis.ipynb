{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../kdd99/kddcup.data_10_percent_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = [\n",
    "    'duration',\n",
    "    'protocol_type',\n",
    "    'service',\n",
    "    'flag',\n",
    "    'src_bytes',\n",
    "    'dst_bytes',\n",
    "    'land',\n",
    "    'wrong_fragment',\n",
    "    'urgent',\n",
    "    'hot',\n",
    "    'num_failed_logins',\n",
    "    'logged_in',\n",
    "    'num_compromised',\n",
    "    'root_shell',\n",
    "    'su_attempted',\n",
    "    'num_root',\n",
    "    'num_file_creations',\n",
    "    'num_shells',\n",
    "    'num_access_files',\n",
    "    'num_outbound_cmds',\n",
    "    'is_host_login',\n",
    "    'is_guest_login',\n",
    "    'count',\n",
    "    'srv_count',\n",
    "    'serror_rate',\n",
    "    'srv_serror_rate',\n",
    "    'rerror_rate',\n",
    "    'srv_rerror_rate',\n",
    "    'same_srv_rate',\n",
    "    'diff_srv_rate',\n",
    "    'srv_diff_host_rate',\n",
    "    'dst_host_count',\n",
    "    'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate',\n",
    "    'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate',\n",
    "    'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate',\n",
    "    'label'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 数值列\n",
    "number_col = df.select_dtypes(include=['number']).columns\n",
    "# 分类变量\n",
    "cat_col = df.columns.difference(number_col)\n",
    "cat_col = cat_col.drop('label')\n",
    "# 将分类变量筛选出来\n",
    "df_cat = df[cat_col].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one-hot编码\n",
    "one_hot_data = pd.get_dummies(df_cat, columns=cat_col)\n",
    "\n",
    "# 将原数据的分类变量去掉\n",
    "one_hot_df = pd.concat([df, one_hot_data],axis=1)\n",
    "one_hot_df.drop(columns=cat_col, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "def normalization(df,col):\n",
    "    for i in col:\n",
    "        arr = df[i]\n",
    "        arr = np.array(arr)\n",
    "        df[i] = minmax_scale.fit_transform(arr.reshape(len(arr),1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalized_df = normalization(one_hot_df.copy(), number_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 为不同的类别进行编码\n",
    "labels = pd.DataFrame(df.label)\n",
    "label_encoder = LabelEncoder()\n",
    "enc_label = labels.apply(label_encoder.fit_transform)\n",
    "normalized_df.label = enc_label\n",
    "label_encoder.classes_\n",
    "label_num = len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = data.drop(columns=['label'])\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LoadData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = torch.tensor(self.X.iloc[index])\n",
    "        y = torch.tensor(self.y.iloc[index])\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = LoadData(X_train, y_train)\n",
    "test_data = LoadData(X_test, y_test)\n",
    "X_dimension = len(X_train.columns)\n",
    "y_dimension = len(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, epochs):\n",
    "\n",
    "    losses = []\n",
    "    iter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch {epoch+1}\\n-----------------\")\n",
    "        for i, (X, y) in enumerate(train_dataloader):\n",
    "            # print(X,y)\n",
    "            X, y = X.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "            y_pred = model(X)\n",
    "            loss = loss_fn(y_pred, y.long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"loss: {loss.item()}\\t[{(i+1)*len(X)}/{len(train_data)}]\")\n",
    "\n",
    "                iter += 1\n",
    "                losses.append(loss.item())\n",
    "\n",
    "    return losses, iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    positive = 0\n",
    "    negative = 0\n",
    "    with torch.no_grad():\n",
    "        iter = 0\n",
    "        loss_sum = 0\n",
    "        for X, y in test_dataloader:\n",
    "            X, y = X.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "            y_pred = model(X)\n",
    "            # print(f\"y_pred: {y_pred.shape}, y: {y.shape}\")\n",
    "            loss = loss_fn(y_pred, y.long())\n",
    "            loss_sum += loss.item()\n",
    "            iter += 1\n",
    "            for item in zip(y_pred, y):\n",
    "                if torch.argmax(item[0]) == item[1]:\n",
    "                    positive += 1\n",
    "                else:\n",
    "                    negative += 1\n",
    "    acc = positive / (positive + negative)\n",
    "    avg_loss = loss_sum / iter\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Average Loss:\", avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_value_plot(losses, iter):\n",
    "    plt.figure()\n",
    "    plt.plot([i for i in range(1, iter+1)], losses)\n",
    "    plt.xlabel('Iterations (×100)')\n",
    "    plt.ylabel('Loss Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(X_dimension, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, y_dimension)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.flatten(X)\n",
    "        logits = self.network(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=118, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=23, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DNN_model = DNN()\n",
    "DNN_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "is_trained = False\n",
    "epochs = 5\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(DNN_model.parameters(), lr=lr, momentum=momentum)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = './kdd99/'\n",
    "timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S_')\n",
    "old_model_name = ''\n",
    "new_model_name = timestamp + 'DNN_model.pth'\n",
    "\n",
    "if old_model_name != '':\n",
    "    DNN_model.load_state_dict(torch.load(old_model_name))\n",
    "else:\n",
    "    losses, iter = train(DNN_model, optimizer, loss_fn, epochs)\n",
    "    torch.save(DNN_model.state_dict(), new_model_name)\n",
    "\n",
    "    loss_value_plot(losses, iter)\n",
    "    plt.savefig(path + timestamp + 'DNN_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test(DNN_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv1d(1, 3, kernel_size=2),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "            nn.Conv1d(3, 8, kernel_size=2),\n",
    "            nn.MaxPool1d(2, 2),\n",
    "            nn.Conv1d(8, 16, kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(432, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, y_dimension)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.backbone(X)\n",
    "        X = self.flatten(X)\n",
    "        logits = self.fc(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\document\\研一上\\信息安全技术\\code\\old\\KDD99_analysis.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/document/%E7%A0%94%E4%B8%80%E4%B8%8A/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%8A%80%E6%9C%AF/code/old/KDD99_analysis.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m CNN_model \u001b[39m=\u001b[39m CNN()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/document/%E7%A0%94%E4%B8%80%E4%B8%8A/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8%E6%8A%80%E6%9C%AF/code/old/KDD99_analysis.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m CNN_model\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[1;32mc:\\Users\\honndaj\\.conda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[1;32mc:\\Users\\honndaj\\.conda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\honndaj\\.conda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[39mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[0;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\honndaj\\.conda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mc:\\Users\\honndaj\\.conda\\envs\\d2l\\lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "CNN_model = CNN()\n",
    "CNN_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(CNN_model.parameters(), lr=lr, momentum=momentum)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './kdd99/'\n",
    "timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S_')\n",
    "old_model_name = ''\n",
    "new_model_name = timestamp + 'CNN_model.pth'\n",
    "\n",
    "if old_model_name != '':\n",
    "    CNN_model.load_state_dict(torch.load(old_model_name))\n",
    "else:\n",
    "    losses, iter = train(CNN_model, optimizer, loss_fn, epochs)\n",
    "    torch.save(CNN_model.state_dict(), path + new_model_name)\n",
    "\n",
    "    loss_value_plot(losses, iter)\n",
    "    plt.savefig(path + timestamp + 'CNN_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test(CNN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(7,), stride=(2,), padding=(3,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(64, 128, kernel_size=(1,), stride=(2,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(128, 256, kernel_size=(1,), stride=(2,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): Sequential(\n",
       "    (0): Residual(\n",
       "      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv3): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): Residual(\n",
       "      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): AdaptiveAvgPool1d(output_size=1)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=512, out_features=23, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Residual(nn.Module): \n",
    "    def __init__(self, input_channels, num_channels,\n",
    "                 use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(input_channels, num_channels,\n",
    "                               kernel_size=3, padding=1, stride=strides)\n",
    "        self.conv2 = nn.Conv1d(num_channels, num_channels,\n",
    "                               kernel_size=3, padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = nn.Conv1d(input_channels, num_channels,\n",
    "                                   kernel_size=1, stride=strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "        self.bn1 = nn.BatchNorm1d(num_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(num_channels)\n",
    "\n",
    "    def forward(self, X):\n",
    "        Y = F.relu(self.bn1(self.conv1(X)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X = self.conv3(X)\n",
    "        Y += X\n",
    "        return F.relu(Y)\n",
    "\n",
    "def resnet_block(input_channels, num_channels, num_residuals,\n",
    "                 first_block=False):\n",
    "    blk = []\n",
    "    for i in range(num_residuals):\n",
    "        if i == 0 and not first_block:\n",
    "            blk.append(Residual(input_channels, num_channels,\n",
    "                                use_1x1conv=True, strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels, num_channels))\n",
    "    return blk\n",
    "\n",
    "b1 = nn.Sequential(nn.Conv1d(1, 64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm1d(64), nn.ReLU(),\n",
    "                   nn.MaxPool1d(kernel_size=3, stride=2, padding=1))\n",
    "b2 = nn.Sequential(*resnet_block(64, 64, 2, first_block=True))\n",
    "b3 = nn.Sequential(*resnet_block(64, 128, 2))\n",
    "b4 = nn.Sequential(*resnet_block(128, 256, 2))\n",
    "b5 = nn.Sequential(*resnet_block(256, 512, 2))\n",
    "\n",
    "resnet_model = nn.Sequential(b1, b2, b3, b4, b5,\n",
    "                    nn.AdaptiveAvgPool1d((1)),\n",
    "                    nn.Flatten(), nn.Linear(512, label_num))\n",
    "resnet_model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7])\n",
      "AdaptiveAvgPool1d output shape:\t torch.Size([1, 512, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 23])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 224), device = device)\n",
    "for layer in resnet_model:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_trained = False\n",
    "epochs = 5\n",
    "lr = 1e-3 \n",
    "momentum = 0.9\n",
    "optimizer = torch.optim.SGD(resnet_model.parameters(), lr=lr)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "-----------------\n",
      "loss: 2.7919507026672363\t[128/395216]\n",
      "loss: 0.10325092077255249\t[12928/395216]\n",
      "loss: 0.12122007459402084\t[25728/395216]\n",
      "loss: 0.06511908769607544\t[38528/395216]\n",
      "loss: 0.07444724440574646\t[51328/395216]\n",
      "loss: 0.04308005049824715\t[64128/395216]\n",
      "loss: 0.07678329199552536\t[76928/395216]\n",
      "loss: 0.021738100796937943\t[89728/395216]\n",
      "loss: 0.07202157378196716\t[102528/395216]\n",
      "loss: 0.013766096904873848\t[115328/395216]\n",
      "loss: 0.018277285620570183\t[128128/395216]\n",
      "loss: 0.03003612719476223\t[140928/395216]\n",
      "loss: 0.011348562315106392\t[153728/395216]\n",
      "loss: 0.005721363704651594\t[166528/395216]\n",
      "loss: 0.012138902209699154\t[179328/395216]\n",
      "loss: 0.0050987065769732\t[192128/395216]\n",
      "loss: 0.005431415978819132\t[204928/395216]\n",
      "loss: 0.003758478444069624\t[217728/395216]\n",
      "loss: 0.019388873130083084\t[230528/395216]\n",
      "loss: 0.011002158746123314\t[243328/395216]\n",
      "loss: 0.011393379420042038\t[256128/395216]\n",
      "loss: 0.005530799273401499\t[268928/395216]\n",
      "loss: 0.02788977324962616\t[281728/395216]\n",
      "loss: 0.006581881549209356\t[294528/395216]\n",
      "loss: 0.0036829933524131775\t[307328/395216]\n",
      "loss: 0.05036287382245064\t[320128/395216]\n",
      "loss: 0.016314035281538963\t[332928/395216]\n",
      "loss: 0.02868543565273285\t[345728/395216]\n",
      "loss: 0.005457152612507343\t[358528/395216]\n",
      "loss: 0.00599410617724061\t[371328/395216]\n",
      "loss: 0.013320882804691792\t[384128/395216]\n",
      "epoch 2\n",
      "-----------------\n",
      "loss: 0.0071987551636993885\t[128/395216]\n",
      "loss: 0.005679850932210684\t[12928/395216]\n",
      "loss: 0.00422913720831275\t[25728/395216]\n",
      "loss: 0.004817881155759096\t[38528/395216]\n",
      "loss: 0.005105251912027597\t[51328/395216]\n",
      "loss: 0.00418311171233654\t[64128/395216]\n",
      "loss: 0.003268891479820013\t[76928/395216]\n",
      "loss: 0.0023712273687124252\t[89728/395216]\n",
      "loss: 0.036966439336538315\t[102528/395216]\n",
      "loss: 0.0029788033571094275\t[115328/395216]\n",
      "loss: 0.0027424655854701996\t[128128/395216]\n",
      "loss: 0.00811455212533474\t[140928/395216]\n",
      "loss: 0.0022502467036247253\t[153728/395216]\n",
      "loss: 0.00197949493303895\t[166528/395216]\n",
      "loss: 0.0035207539331167936\t[179328/395216]\n",
      "loss: 0.0014602686278522015\t[192128/395216]\n",
      "loss: 0.0018007366452366114\t[204928/395216]\n",
      "loss: 0.0011860515223816037\t[217728/395216]\n",
      "loss: 0.010860728099942207\t[230528/395216]\n",
      "loss: 0.004697508178651333\t[243328/395216]\n",
      "loss: 0.0035092090256512165\t[256128/395216]\n",
      "loss: 0.0014110459014773369\t[268928/395216]\n",
      "loss: 0.011110655963420868\t[281728/395216]\n",
      "loss: 0.005028937477618456\t[294528/395216]\n",
      "loss: 0.001690764562226832\t[307328/395216]\n",
      "loss: 0.0315847173333168\t[320128/395216]\n",
      "loss: 0.004986778367310762\t[332928/395216]\n",
      "loss: 0.011373130604624748\t[345728/395216]\n",
      "loss: 0.002246216172352433\t[358528/395216]\n",
      "loss: 0.007018189877271652\t[371328/395216]\n",
      "loss: 0.004883295390754938\t[384128/395216]\n",
      "epoch 3\n",
      "-----------------\n",
      "loss: 0.002714515198022127\t[128/395216]\n",
      "loss: 0.0022785156033933163\t[12928/395216]\n",
      "loss: 0.0019882109481841326\t[25728/395216]\n",
      "loss: 0.0017640338046476245\t[38528/395216]\n",
      "loss: 0.002384477760642767\t[51328/395216]\n",
      "loss: 0.0021608355455100536\t[64128/395216]\n",
      "loss: 0.0015662370715290308\t[76928/395216]\n",
      "loss: 0.0011727233650162816\t[89728/395216]\n",
      "loss: 0.02785167098045349\t[102528/395216]\n",
      "loss: 0.0021876830141991377\t[115328/395216]\n",
      "loss: 0.0013182539260014892\t[128128/395216]\n",
      "loss: 0.005036189220845699\t[140928/395216]\n",
      "loss: 0.0012991551775485277\t[153728/395216]\n",
      "loss: 0.0016020623734220862\t[166528/395216]\n",
      "loss: 0.0017722148913890123\t[179328/395216]\n",
      "loss: 0.0008392603485845029\t[192128/395216]\n",
      "loss: 0.0013358526630327106\t[204928/395216]\n",
      "loss: 0.0006666462286375463\t[217728/395216]\n",
      "loss: 0.008479582145810127\t[230528/395216]\n",
      "loss: 0.0034863161854445934\t[243328/395216]\n",
      "loss: 0.002118605887517333\t[256128/395216]\n",
      "loss: 0.0006446235347539186\t[268928/395216]\n",
      "loss: 0.006497415713965893\t[281728/395216]\n",
      "loss: 0.003887273371219635\t[294528/395216]\n",
      "loss: 0.001273245783522725\t[307328/395216]\n",
      "loss: 0.021104514598846436\t[320128/395216]\n",
      "loss: 0.0023299967870116234\t[332928/395216]\n",
      "loss: 0.006919988431036472\t[345728/395216]\n",
      "loss: 0.0014182182494550943\t[358528/395216]\n",
      "loss: 0.006635594647377729\t[371328/395216]\n",
      "loss: 0.0027797140646725893\t[384128/395216]\n",
      "epoch 4\n",
      "-----------------\n",
      "loss: 0.001613023690879345\t[128/395216]\n",
      "loss: 0.0013950865250080824\t[12928/395216]\n",
      "loss: 0.0013555472251027822\t[25728/395216]\n",
      "loss: 0.0009946252685040236\t[38528/395216]\n",
      "loss: 0.0014855772024020553\t[51328/395216]\n",
      "loss: 0.0014522533165290952\t[64128/395216]\n",
      "loss: 0.001024582190439105\t[76928/395216]\n",
      "loss: 0.0007590944878757\t[89728/395216]\n",
      "loss: 0.022383738309144974\t[102528/395216]\n",
      "loss: 0.0017273740377277136\t[115328/395216]\n",
      "loss: 0.0008197766146622598\t[128128/395216]\n",
      "loss: 0.003744963789358735\t[140928/395216]\n",
      "loss: 0.0009090489475056529\t[153728/395216]\n",
      "loss: 0.0012370204785838723\t[166528/395216]\n",
      "loss: 0.0010940940119326115\t[179328/395216]\n",
      "loss: 0.0005840593366883695\t[192128/395216]\n",
      "loss: 0.0010276519460603595\t[204928/395216]\n",
      "loss: 0.000449406128609553\t[217728/395216]\n",
      "loss: 0.006147031672298908\t[230528/395216]\n",
      "loss: 0.0027904892340302467\t[243328/395216]\n",
      "loss: 0.0015117180300876498\t[256128/395216]\n",
      "loss: 0.00043270381866022944\t[268928/395216]\n",
      "loss: 0.00443584518507123\t[281728/395216]\n",
      "loss: 0.0027609295211732388\t[294528/395216]\n",
      "loss: 0.001048741745762527\t[307328/395216]\n",
      "loss: 0.01427085418254137\t[320128/395216]\n",
      "loss: 0.0014775312738493085\t[332928/395216]\n",
      "loss: 0.0047237160615623\t[345728/395216]\n",
      "loss: 0.0010407736990600824\t[358528/395216]\n",
      "loss: 0.005649741739034653\t[371328/395216]\n",
      "loss: 0.0017875352641567588\t[384128/395216]\n",
      "epoch 5\n",
      "-----------------\n",
      "loss: 0.0011652964167296886\t[128/395216]\n",
      "loss: 0.0010275059612467885\t[12928/395216]\n",
      "loss: 0.0010242643766105175\t[25728/395216]\n",
      "loss: 0.0006828452460467815\t[38528/395216]\n",
      "loss: 0.0010887683602049947\t[51328/395216]\n",
      "loss: 0.0011287606321275234\t[64128/395216]\n",
      "loss: 0.0008035924402065575\t[76928/395216]\n",
      "loss: 0.0005556646501645446\t[89728/395216]\n",
      "loss: 0.018389036878943443\t[102528/395216]\n",
      "loss: 0.0013518964406102896\t[115328/395216]\n",
      "loss: 0.0005983583978377283\t[128128/395216]\n",
      "loss: 0.0032258101273328066\t[140928/395216]\n",
      "loss: 0.0006917837308719754\t[153728/395216]\n",
      "loss: 0.0008824406540952623\t[166528/395216]\n",
      "loss: 0.0007872384157963097\t[179328/395216]\n",
      "loss: 0.00044416432501748204\t[192128/395216]\n",
      "loss: 0.0008161442237906158\t[204928/395216]\n",
      "loss: 0.00035144234425388277\t[217728/395216]\n",
      "loss: 0.004730241373181343\t[230528/395216]\n",
      "loss: 0.0022541729267686605\t[243328/395216]\n",
      "loss: 0.0011816981714218855\t[256128/395216]\n",
      "loss: 0.0003247826243750751\t[268928/395216]\n",
      "loss: 0.003150548553094268\t[281728/395216]\n",
      "loss: 0.0021224352531135082\t[294528/395216]\n",
      "loss: 0.0008361522923223674\t[307328/395216]\n",
      "loss: 0.009609282948076725\t[320128/395216]\n",
      "loss: 0.0010125617263838649\t[332928/395216]\n",
      "loss: 0.003640905488282442\t[345728/395216]\n",
      "loss: 0.0008172276429831982\t[358528/395216]\n",
      "loss: 0.005176534876227379\t[371328/395216]\n",
      "loss: 0.0013301073340699077\t[384128/395216]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGwCAYAAACtlb+kAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAABGb0lEQVR4nO3deXhU5d3/8c/MJJksZGFLQkIgKCqrAWULqNBCRYsK8pQiVUGt+tNiC2q19XGrWo3LQ3EHqUpEa1UsYKVuMSxCQZBN2UG2sCRhTYaErDPn90fIgTEsCZxhTpL367rm0jlzZuZ7Z5l8uL/n3MdhGIYhAACABswZ7AIAAAACjcADAAAaPAIPAABo8Ag8AACgwSPwAACABo/AAwAAGjwCDwAAaPBCgl3Auebz+bRnzx5FR0fL4XAEuxwAAFALhmHo8OHDSkpKktNZ9/maRhd49uzZo5SUlGCXAQAAzsDOnTvVunXrOj+v0QWe6OhoSVVfsJiYmCBXAwAAasPj8SglJcX8O15XjS7wVLexYmJiCDwAANQzZ3o4CgctAwCABo/AAwAAGjwCDwAAaPAIPAAAoMEj8AAAgAaPwAMAABo8Ag8AAGjwCDwAAKDBI/AAAIAGj8ADAAAaPAIPAABo8Ag8AACgwWt0Fw8NlLJKr/YXlcvpkFrFRgS7HAAAcBxmeCyyZrdH/Z6doxumfBvsUgAAwE8QeCziPHq1ep9hBLcQAABQA4HHIk5HVeLx+YJcCAAAqIHAYxHX0SkeZngAALAfAo9FHLS0AACwLQKPRapbWl5aWgAA2A6BxyLVLS2DGR4AAGyHwGMRztICAMC+CDwWcZgtLQIPAAB2Q+CxiMtR3dIKciEAAKAGAo9FzHV4SDwAANgOgcci1aelewk8AADYDoHHIscWHgxyIQAAoAYCj0WcDk5LBwDArgg8Fqk+LZ2ztAAAsB8Cj0UcDlpaAADYFYHHItXH8Ei0tQAAsBsCj0WOyzvM8gAAYDMEHotUt7QkjuMBAMBuCDwWOb6lxeKDAADYC4HHIse3tMg7AADYC4HHIs7jW1okHgAAbIXAY5HjAw8tLQAA7IXAYxG/lpYveHUAAICaCDwWoaUFAIB9EXgs4uQsLQAAbIvAY6HqzEPgAQDAXgg8Fqpua/k4hgcAAFsh8Fiouq3FDA8AAPZC4LEQLS0AAOyJwGMhWloAANgTgcdCLgctLQAA7CiogScjI0M9e/ZUdHS04uPjNWzYMG3cuPGUz8nMzJTD4fC7hYeHn6OKT81BSwsAAFsKauCZP3++xo4dq2+//VZZWVmqqKjQlVdeqeLi4lM+LyYmRrm5ueZtx44d56jiU+OgZQAA7CkkmG/+xRdf+N3PzMxUfHy8li9friuuuOKkz3M4HEpMTAx0eXV2rKUV5EIAAIAfWx3DU1hYKElq1qzZKfcrKipS27ZtlZKSoqFDh2rt2rUn3besrEwej8fvFigOjuEBAMCWbBN4fD6fxo8fr379+qlLly4n3e+iiy7S22+/rU8++UTvvfeefD6f+vbtq127dp1w/4yMDMXGxpq3lJSUQA3h2GnpnKUFAICtOAzDHtMRd999tz7//HMtXLhQrVu3rvXzKioq1LFjR40aNUpPPfVUjcfLyspUVlZm3vd4PEpJSVFhYaFiYmIsqb1an2eylecp1ezfX6YuybGWvjYAAI2Zx+NRbGzsGf/9DuoxPNXuuecezZ49W998802dwo4khYaGqnv37vrxxx9P+Ljb7Zbb7baizNNycdAyAAC2FNSWlmEYuueeezRz5kzNmTNH7dq1q/NreL1erV69Wq1atQpAhXVz7LT04NYBAAD8BXWGZ+zYsXr//ff1ySefKDo6Wnl5eZKk2NhYRURESJJGjx6t5ORkZWRkSJKefPJJ9enTR+3bt1dBQYFeeOEF7dixQ7fffnvQxlGteqVlL4kHAABbCWrgmTRpkiRpwIABftunTp2qW265RZKUk5Mjp/PYRNShQ4d0xx13KC8vT02bNtWll16qRYsWqVOnTueq7JOqbmnZ5LAoAABwVFADT22Cwbx58/zuT5w4URMnTgxQRWeHlhYAAPZkm9PSGwJaWgAA2BOBx0LVKy3T0gIAwF4IPBaipQUAgD0ReCxktrSY4QEAwFYIPBZi4UEAAOyJwGOh6mtpcQwPAAD2QuCxkMM8SyvIhQAAAD8EHgvR0gIAwJ4IPBaipQUAgD0ReCxESwsAAHsi8FioeuFBWloAANgLgcdC1dc4JfAAAGAvBB4LOc1LSwS5EAAA4IfAYyEHFw8FAMCWCDwWcpnX0iLwAABgJwQeC9HSAgDAngg8FnJw8VAAAGyJwGMhF2dpAQBgSwQeCznNdXiCXAgAAPBD4LGQGXhIPAAA2AqBx0JOLh4KAIAtEXgs5DRPSw9uHQAAwB+Bx0K0tAAAsCcCj4WcXDwUAABbIvBYiJYWAAD2ROCxEDM8AADYE4HHQuZZWkzxAABgKwQeC9HSAgDAngg8FnJyLS0AAGyJwGMhl7P6aukEHgAA7ITAYyGH2dIi8AAAYCcEHgtx8VAAAOyJwGMh86BlEg8AALZC4LEQFw8FAMCeCDwWoqUFAIA9EXgsVN3S8pJ4AACwFQKPhVwOTksHAMCOCDwWctDSAgDAlgg8FmKlZQAA7InAYyHX0a8mLS0AAOyFwGMhs6XlC3IhAADAD4HHQrS0AACwJwKPhapbWiw8CACAvRB4LOQ0T0sPciEAAMAPgcdC1cfwsPAgAAD2QuCxkKv64qFM8QAAYCsEHgtVXzyUvAMAgL0QeCxESwsAAHsi8FjIZV5agsADAICdEHgs5DSP4QluHQAAwF9QA09GRoZ69uyp6OhoxcfHa9iwYdq4ceNpnzd9+nR16NBB4eHh6tq1qz777LNzUO3pOblaOgAAthTUwDN//nyNHTtW3377rbKyslRRUaErr7xSxcXFJ33OokWLNGrUKP32t7/VypUrNWzYMA0bNkxr1qw5h5Wf2NG8w0rLAADYjMOw0XTEvn37FB8fr/nz5+uKK6444T4jR45UcXGxZs+ebW7r06ePunXrpsmTJ9fYv6ysTGVlZeZ9j8ejlJQUFRYWKiYmxtL6Z6zYpfs++l5XXNhS027rZelrAwDQmHk8HsXGxp7x329bHcNTWFgoSWrWrNlJ91m8eLEGDRrkt23w4MFavHjxCffPyMhQbGyseUtJSbGu4J+gpQUAgD3ZJvD4fD6NHz9e/fr1U5cuXU66X15enhISEvy2JSQkKC8v74T7P/TQQyosLDRvO3futLTu45ktLY5aBgDAVkKCXUC1sWPHas2aNVq4cKGlr+t2u+V2uy19zZNxOTktHQAAO7JF4Lnnnns0e/ZsffPNN2rduvUp901MTFR+fr7ftvz8fCUmJgayxFpxmuvwBLkQAADgJ6gtLcMwdM8992jmzJmaM2eO2rVrd9rnpKenKzs7229bVlaW0tPTA1VmrZnr8JB4AACwlaDO8IwdO1bvv/++PvnkE0VHR5vH4cTGxioiIkKSNHr0aCUnJysjI0OSNG7cOPXv318TJkzQkCFD9MEHH2jZsmWaMmVK0MZRzclKywAA2FJQZ3gmTZqkwsJCDRgwQK1atTJvH374oblPTk6OcnNzzft9+/bV+++/rylTpigtLU0ff/yxZs2adcoDnc8VWloAANhTUGd4anP69rx582psGzFihEaMGBGAis6O82h8ZIYHAAB7sc1p6Q0BLS0AAOyJwGMhM/D4glwIAADwQ+CxEDM8AADYE4HHQhzDAwCAPRF4LMRZWgAA2BOBx0K0tAAAsCcCj4Vc1S0tpngAALAVAo+FHLS0AACwJQKPhWhpAQBgTwQeC3HxUAAA7InAYyHO0gIAwJ4IPBaipQUAgD0ReCzEwoMAANgTgcdCLlpaAADYEoHHQg5aWgAA2BKBx0LVZ2l5meIBAMBWCDwWch1NPEzwAABgLwQeC3GWFgAA9kTgsZCDlhYAALZE4LEQLS0AAOyJwGMhWloAANgTgcdCZkuLwAMAgK0QeCxUvfCgYUgGoQcAANsg8FiouqUlcRwPAAB2QuCx0PGBh+N4AACwDwKPhZzHfTU5jgcAAPsg8FiIlhYAAPZE4LEQLS0AAOyJwGMhv5YWqy0DAGAbBB4L+c/wBLEQAADg56wCT2lpqVV1NAj+x/CQeAAAsIs6Bx6fz6ennnpKycnJatKkibZu3SpJevTRR/XWW29ZXmB94jyWd2hpAQBgI3UOPH/961+VmZmp559/XmFhYeb2Ll266M0337S0uPrG4XCYl5cg7wAAYB91DjzTpk3TlClTdOONN8rlcpnb09LStGHDBkuLq4+c5uUlSDwAANhFnQPP7t271b59+xrbfT6fKioqLCmqPnNyAVEAAGynzoGnU6dOWrBgQY3tH3/8sbp3725JUfVZ9QwPLS0AAOwjpK5PeOyxxzRmzBjt3r1bPp9PM2bM0MaNGzVt2jTNnj07EDXWK2bgIfEAAGAbdZ7hGTp0qD799FN9/fXXioqK0mOPPab169fr008/1S9+8YtA1FivOM2Dlgk8AADYRZ1neCTp8ssvV1ZWltW1NAhOJy0tAADshpWWLXbsGB4SDwAAdlHnGR6n0ynHcSsK/5TX6z2rguo7s6XFFA8AALZR58Azc+ZMv/sVFRVauXKl3nnnHT3xxBOWFVZfuWhpAQBgO3UOPEOHDq2x7Ve/+pU6d+6sDz/8UL/97W8tKay+ctDSAgDAdiw7hqdPnz7Kzs626uXqLc7SAgDAfiwJPCUlJXr55ZeVnJxsxcvVay5zHZ4gFwIAAEx1bmk1bdrU76BlwzB0+PBhRUZG6r333rO0uPqIlhYAAPZT58AzceJEv8DjdDrVsmVL9e7dW02bNrW0uPrIeXTOjMADAIB91Dnw3HLLLQEoo+FwMcMDAIDt1Crw/PDDD7V+wYsvvviMi2kIuHgoAAD2U6vA061bNzkcDhmnmbVwOBx1Wnjwm2++0QsvvKDly5crNzdXM2fO1LBhw066/7x58/Szn/2sxvbc3FwlJibW+n0DycHCgwAA2E6tAs+2bdsC8ubFxcVKS0vTbbfdpuHDh9f6eRs3blRMTIx5Pz4+PhDlnZHqGR4vLS0AAGyjVoGnbdu2AXnzq6++WldffXWdnxcfH6+4uLha7VtWVqaysjLzvsfjqfP71UX1SsvkHQAA7OOMrpYuSevWrVNOTo7Ky8v9tl933XVnXdTpdOvWTWVlZerSpYv+8pe/qF+/fifdNyMj45xe8oLT0gEAsJ86B56tW7fq+uuv1+rVq/2O66n+Qx/Ii4e2atVKkydPVo8ePVRWVqY333xTAwYM0JIlS3TJJZec8DkPPfSQ7rvvPvO+x+NRSkpKwGqsXmnZyzE8AADYRp0Dz7hx49SuXTtlZ2erXbt2Wrp0qQ4cOKD7779f//d//xeIGk0XXXSRLrroIvN+3759tWXLFk2cOFHvvvvuCZ/jdrvldrsDWtfxaGkBAGA/db60xOLFi/Xkk0+qRYsWcjqdcjqduuyyy5SRkaE//OEPgajxlHr16qUff/zxnL/vydDSAgDAfuoceLxer6KjoyVJLVq00J49eyRVHdi8ceNGa6urhVWrVqlVq1bn/H1PhpYWAAD2U+eWVpcuXfT999+rXbt26t27t55//nmFhYVpypQpOu+88+r0WkVFRX6zM9u2bdOqVavUrFkztWnTRg899JB2796tadOmSZJefPFFtWvXTp07d1ZpaanefPNNzZkzR1999VVdhxEwLhYeBADAduoceB555BEVFxdLkp588kldc801uvzyy9W8eXN9+OGHdXqtZcuW+S0kWH1w8ZgxY5SZmanc3Fzl5OSYj5eXl+v+++/X7t27FRkZqYsvvlhff/31CRcjDJbqdXhOt0gjAAA4dxxGLf8y9+jRQ7fffrt+85vf+C36J0kHDx6scRV1u/J4PIqNjVVhYWGNcVhh5BuLtWTbQb36m+665uIky18fAIDG6Gz/ftf6GJ60tDQ9+OCDatWqlUaPHq158+aZjzVr1qxehJ1zofosLVpaAADYR60Dz1tvvaW8vDy99tprysnJ0cCBA9W+fXs988wz2r17dyBrrFdoaQEAYD91OksrMjJSt9xyi+bNm6dNmzbphhtu0BtvvKHU1FQNGTJEM2bMCFSd9YZ58VACDwAAtlHn09KrnX/++frrX/+q7du365///Ke+/fZbjRgxwsra6qXqlpbXF+RCAACA6YyvpSVJ8+bN09SpU/Wvf/1LISEhuuOOO6yqq95ysvAgAAC2U+fAs2vXLmVmZiozM1Nbt27V5Zdfrtdff10jRoxQREREIGqsV6oXHuQYHgAA7KPWgeejjz7S22+/rezsbMXHx2vMmDG67bbb1L59+0DWV+9Uz/DQ0gIAwD5qHXhuuukmDRkyRDNnztQvf/lLOZ1nfPhPg0ZLCwAA+6l14Nm1a5fi4+MDWUuDUJ0DaWkBAGAftZ6mIezUjsNsaRF4AACwC/pSFuPioQAA2A+Bx2JOFh4EAMB2CDwW46BlAADsp86BZ+fOndq1a5d5f+nSpRo/frymTJliaWH1lZOLhwIAYDt1Djy/+c1vNHfuXElSXl6efvGLX2jp0qV6+OGH9eSTT1peYH1DSwsAAPupc+BZs2aNevXqJalqMcIuXbpo0aJF+sc//qHMzEyr66t3zJYWUzwAANhGnQNPRUWF3G63JOnrr7/WddddJ0nq0KGDcnNzra2uHqKlBQCA/dQ58HTu3FmTJ0/WggULlJWVpauuukqStGfPHjVv3tzyAusbWloAANhPnQPPc889pzfeeEMDBgzQqFGjlJaWJkn697//bba6GjNaWgAA2E+dr5Y+YMAA7d+/Xx6PR02bNjW333nnnYqMjLS0uPrIycKDAADYTp1neEpKSlRWVmaGnR07dujFF1/Uxo0bufyEWIcHAAA7qnPgGTp0qKZNmyZJKigoUO/evTVhwgQNGzZMkyZNsrzA+ubYMTzBrQMAABxT58CzYsUKXX755ZKkjz/+WAkJCdqxY4emTZuml19+2fIC6xuXkxkeAADsps6B58iRI4qOjpYkffXVVxo+fLicTqf69OmjHTt2WF5gfePgoGUAAGynzoGnffv2mjVrlnbu3Kkvv/xSV155pSRp7969iomJsbzA+oaWFgAA9lPnwPPYY4/pj3/8o1JTU9WrVy+lp6dLqprt6d69u+UF1je0tAAAsJ86n5b+q1/9Spdddplyc3PNNXgkaeDAgbr++ustLa4+cnCWFgAAtlPnwCNJiYmJSkxMNK+a3rp1axYdPIqVlgEAsJ86t7R8Pp+efPJJxcbGqm3btmrbtq3i4uL01FNPyefzBaLGeqV6HR4vXwoAAGyjzjM8Dz/8sN566y09++yz6tevnyRp4cKF+stf/qLS0lI9/fTTlhdZn1Qfw2MwwwMAgG3UOfC88847evPNN82rpEvSxRdfrOTkZP3ud79r9IHHQUsLAADbqXNL6+DBg+rQoUON7R06dNDBgwctKao+o6UFAID91DnwpKWl6dVXX62x/dVXX/U7a6uxcjloaQEAYDd1bmk9//zzGjJkiL7++mtzDZ7Fixdr586d+uyzzywvsL6hpQUAgP3UeYanf//+2rRpk66//noVFBSooKBAw4cP18aNG81rbDVmZkuLvAMAgG2c0To8SUlJNQ5O3rVrl+68805NmTLFksLqK1ZaBgDAfuo8w3MyBw4c0FtvvWXVy9Vb1QsPcgwPAAD2YVngQRWHeZYWgQcAALsg8FjsWEsryIUAAAATgcditLQAALCfWh+0PHz48FM+XlBQcLa1NAjHrpYe5EIAAICp1oEnNjb2tI+PHj36rAuq71wcwwMAgO3UOvBMnTo1kHU0GM6jTUJOSwcAwD44hsdiTvPSEkEuBAAAmAg8FnPS0gIAwHYIPBZzOlhpGQAAuyHwWOzYaenBrQMAABxD4LGYudIyiQcAANsg8FiMi4cCAGA/QQ0833zzja699lolJSXJ4XBo1qxZp33OvHnzdMkll8jtdqt9+/bKzMwMeJ11Ud3S4phlAADsI6iBp7i4WGlpaXrttddqtf+2bds0ZMgQ/exnP9OqVas0fvx43X777fryyy8DXGntmQctk3gAALCNWi88GAhXX321rr766lrvP3nyZLVr104TJkyQJHXs2FELFy7UxIkTNXjw4ECVWSdOWloAANhOvTqGZ/HixRo0aJDftsGDB2vx4sUnfU5ZWZk8Ho/fLZBoaQEAYD/1KvDk5eUpISHBb1tCQoI8Ho9KSkpO+JyMjAzFxsaat5SUlIDWSEsLAAD7qVeB50w89NBDKiwsNG87d+4M6Pux8CAAAPYT1GN46ioxMVH5+fl+2/Lz8xUTE6OIiIgTPsftdsvtdp+L8iQd39Ii8AAAYBf1aoYnPT1d2dnZftuysrKUnp4epIpqOnbQcpALAQAApqAGnqKiIq1atUqrVq2SVHXa+apVq5STkyOpqh01evRoc/+77rpLW7du1YMPPqgNGzbo9ddf10cffaR77703GOWfEC0tAADsJ6iBZ9myZerevbu6d+8uSbrvvvvUvXt3PfbYY5Kk3NxcM/xIUrt27fSf//xHWVlZSktL04QJE/Tmm2/a5pR0iZYWAAB2FNRjeAYMGCDjFMHgRKsoDxgwQCtXrgxgVWfn2FlaQS4EAACY6tUxPPUB19ICAMB+CDwWc9DSAgDAdgg8Fjt20HKQCwEAACYCj8XMlhaJBwAA2yDwWIyztAAAsB8Cj8UctLQAALAdAo/FXFw8FAAA2yHwWIyVlgEAsB8Cj8WOnZYe3DoAAMAxBB6LVV881MsMDwAAtkHgsVj1MTynumQGAAA4twg8FnPS0gIAwHYIPBarPi3dS+IBAMA2CDwWq15pWaKtBQCAXRB4LHZc3qGtBQCATRB4LFbd0pJoawEAYBcEHosd39Ji8UEAAOyBwGOx41ta5B0AAOyBwGMxp4MZHgAA7IbAY7HjAw+rLQMAYA8EHov5tbR8wasDAAAcQ+CxGC0tAADsh8BjMaeTlhYAAHZD4AmAY9fTIvAAAGAHBJ4AcJpXTA9yIQAAQBKBJyCq21qstAwAgD0QeAKAlhYAAPZC4AkAWloAANgLgScAqgMPLS0AAOyBwBMAtLQAALAXAk8AVB+0zAQPAAD2QOAJgOqWFjM8AADYA4EnAAg8AADYC4EnAMxjeLh4KAAAtkDgCQBmeAAAsBcCTwC4nAQeAADshMATAA7ztPTg1gEAAKoQeAKAlhYAAPZC4AkAs6XFFA8AALZA4AkAWloAANgLgScAaGkBAGAvBJ4AcDloaQEAYCcEngCgpQUAgL0QeAKAlhYAAPZC4AmA6rO0vAQeAABsgcATANXX0jIIPAAA2AKBJwAc5kHLQS4EAABIIvAERPUMDy0tAADsgcATANXH8NDSAgDAHmwReF577TWlpqYqPDxcvXv31tKlS0+6b2ZmphwOh98tPDz8HFZ7emZLi7wDAIAtBD3wfPjhh7rvvvv0+OOPa8WKFUpLS9PgwYO1d+/ekz4nJiZGubm55m3Hjh3nsOLTM1taJB4AAGwh6IHnb3/7m+644w7deuut6tSpkyZPnqzIyEi9/fbbJ32Ow+FQYmKieUtISDiHFZ+eefFQWloAANhCUANPeXm5li9frkGDBpnbnE6nBg0apMWLF5/0eUVFRWrbtq1SUlI0dOhQrV279qT7lpWVyePx+N0CrXrhQfIOAAD2ENTAs3//fnm93hozNAkJCcrLyzvhcy666CK9/fbb+uSTT/Tee+/J5/Opb9++2rVr1wn3z8jIUGxsrHlLSUmxfBw/5WClZQAAbCXoLa26Sk9P1+jRo9WtWzf1799fM2bMUMuWLfXGG2+ccP+HHnpIhYWF5m3nzp0Br9HFMTwAANhKSDDfvEWLFnK5XMrPz/fbnp+fr8TExFq9RmhoqLp3764ff/zxhI+73W653e6zrrUuaGkBAGAvQZ3hCQsL06WXXqrs7Gxzm8/nU3Z2ttLT02v1Gl6vV6tXr1arVq0CVWad0dICAMBegjrDI0n33XefxowZox49eqhXr1568cUXVVxcrFtvvVWSNHr0aCUnJysjI0OS9OSTT6pPnz5q3769CgoK9MILL2jHjh26/fbbgzkMP66jMZKVlgEAsIegB56RI0dq3759euyxx5SXl6du3brpiy++MA9kzsnJkdN5bCLq0KFDuuOOO5SXl6emTZvq0ksv1aJFi9SpU6dgDaEGJwsPAgBgKw6jkV3/wOPxKDY2VoWFhYqJiQnIe4z9xwr9Z3WunhzaWaPTUwPyHgAANCZn+/e73p2lVR84jy48yFlaAADYA4EnAKovLUHeAQDAHgg8AXDstHQSDwAAdkDgCYDqwENLCwAAeyDwBAAtLQAA7IXAEwBOFh4EAMBWCDwBUL1skI8pHgAAbIHAEwAsPAgAgL0QeAKAlhYAAPZC4AmAYwctE3gAALADAk8AVK+0TOABAMAeCDwBwDE8AADYC4EnAGhpAQBgLwSeADBbWkzxAABgCwSeAKClBQCAvRB4AoCWFgAA9kLgCQCXg5YWAAB2QuAJAActLQAAbIXAEwCstAwAgL0QeALAVX3xUAIPAAC2QOAJALOl5QtyIQAAQBKBJyBoaQEAYC8EngCobml5CTwAANgCgScAqmd4yDsAANgDgScAHLS0AACwFQJPAFSvtOxlIR4AAGyBwBMALictLQAA7ITAEwC0tAAAsBcCTwDQ0gIAwF4IPAHg4lpaAADYCoEnAI6dlk7iAQDADgg8AXA073AMDwAANkHgCYDqs7S85B0AAGyBwBMAtLQAALAXAk8A0NICAMBeCDwBYLa0OE0LAABbIPAEgJPT0gEAsBUCTwBULzxoGIZ2Hjyip/+zTj/sKghqTQAANGYhwS6gIaqe4dm2v1hDXl4gT2mlvlybr7l/HGC2uwAAwLnDDE8AVAee/UXl8pRWSpJyDh7RnA17g1kWAACNFoEnACLdLvP//1//8/Tby9pJkqb+d1uwSgIAoFGjpRUAvVKb6eFfdlSX5Filn99cuwtKlLlouxZtOaANeR51SIwJdokAADQqzPAEQIjLqTuuOE/p5zeXJCXHRWhw5wRJUuZ/t5v7nWhhwtIKr77bfpBFCwEAsBCB5xy5tV9VW2vmyt2avmynRr+9VBc98oVfm8vnM3THtGUaMXmx3luS4/f8z1bn6oHp36uorPKc1g0AQENA4DlHerRtqi7JMSqr9OmBj3/QN5v2qdzr01Oz12nRlv2SpCkLtmrB5qP//80Wc+HCgiPlemD695q+fJfe+3ZH0MYAAEB9ReA5RxwOh37/8wskSa1iw/X7n7fXtWlJ8hnSH/65Ul+tzdP/fblRkhTidGjnwRJlrcuXJGUu2q7icq8k6b1vd9TrFZxLK7wqOToWAADOFQ5aPocGd07Uikd/odiIULmcDpWUe/Xj3iKtz/XozneXS5J+2TVRqc2j9Pq8LXpr4Vb1a99cU48e9+N0SLsOlWjexr0a2DEhiCM5M0fKK3X1SwtUVuHTJ/f0U0JMeLBLAgA0EszwnGPNosLMxQcjwlyafNMlig6vyp1JseHKuP5ijU5PVYjToe+2H9KfZ6xWYUmFzmsZZR4HNG1x/WxrZS7arh0HjijPU6o/Tv9ePpvOVH29Ll9frMkLdhkAAAsReIKsbfMoTbm5hwZ1TNAbN/dQbGSoEmPDdW1akiTpPz/kSpLGDmiv0elt5XBI8zft0/b9xX6vk+8p1XNfbNDzX2xQaUVwWkY7DhTrizV5JwwyhSUVemP+VklVV5NfsHm/3j56wHZxWaXe/XaHFh49fimY/vvjft0+bZnuem+55mzID3Y5Z2xPQYluenOJ/pa1ybZn/BmGoTkb8rXz4JFglwKgEbBF4HnttdeUmpqq8PBw9e7dW0uXLj3l/tOnT1eHDh0UHh6url276rPPPjtHlQZG+vnN9eaYHuraOtbcVr1YoSSlNIvQdd2S1LZ5lPpf2FJS1bE8ZZVerd5VqIdnrtblz83VpHlb9Pq8LRr++iLtOFBc433qylNaoS/X5tUIVyeyeMsBDXl5oe56b7nGvr+iRuh6c8FWFZZU6IL4Jnryus6SpOe/2Kjnvtigy5+fq0dnrdHNby/Rh9/lnOjlz4mCI+W6/6PvzfsPTP9Bew+XBq2eM1VS7tWd7y7Twh/36+Xszfpb1qZgl3RCz32xUbdlLtOQlxdo3R5PsMs5YzsOFCvj8/Vas7sw2KWc1PIdB3XntGX1OsTXF0VllfphV4Ft/6HRmDmMIH9XPvzwQ40ePVqTJ09W79699eKLL2r69OnauHGj4uPja+y/aNEiXXHFFcrIyNA111yj999/X88995xWrFihLl26nPb9PB6PYmNjVVhYqJgYey8A+Ju/f6tFWw7o2eFddUOvNpKkORvydVvmMoW6HDIMqfK42ZQebZtq2/5iHSguV3R4iB66uqOuuLCFkuMiVOkztGpngb7bflDNo8I04KL4Ux5D8+XaPD06a432Hi6TJHVNjtVVXRIVFeZSpc9QqMupi1vHqktyrOZs2Kvf/3Olyit95vMvbdtUfx/dQ82iwnSgqExXPD9XxeVeTb7pEg3unKg7311uHpQtSXGRoSo4UiFJevzaTmb7TpL2HS7T3A17tWTbQSXHhavPec11SdumCg89tqL12TIMQ/e8v1L/WZ2rdi2i5A5xakPeYfW/sKWm3tJTzp9cA63S65PL6ZDDYc210bbsK9KmvMO6OCVOyXERp9y30uvToi0HdKS8Uj1Tm6l5E7ffOMZ9sEr//n6PIsNcOnL0APHHr+2kMempWp/n0epdheqUFKOuybGW1V9Xby7Yqr/+Z715v3lUmD66K13nt2wS8Peu8Prk9RmW/Pws3LxfY99focKSCoW5nHpiaGfd0DMlaF/XE/liTa7+8MEqlVf65HBID/+yo357WTtb1VgbxWWVenPBNi3bcVA39m6jwZ0TbTeG77Yf1Lh/rtSewlIN6hivZ//nYrU47vezPtl3uEylFV6lNIsMdimms/37HfTA07t3b/Xs2VOvvvqqJMnn8yklJUW///3v9ec//7nG/iNHjlRxcbFmz55tbuvTp4+6deumyZMnn/b96lPgOVRcrtW7C3X5BS3MX2yvz9AvJs7X1n1Vsy6xEaHqmdpUd1x+nnqf11y5hSW65/2VWr7jkPk6iTHhOlxaYZ7pVa1jqxglxrjlNarWAIoMcykuMrQqYGzcJ0lq0cStQ0fKT3pmWESoS2WVXvkM6cpOCbqxT1v9/v0V8pRWqkWTMHVsFaOiskqtzClQ1+RY/fuefnI4HDpYXK6RbyxWpc/Q7wacr2Hdk/X8Fxv09wVVba7ubeIkSUfKvNq097B++lMa6nKoWVSYYsJDFR0eopiIUEWHh6qJ2yWvz1Clz1Cl15DXZ6jC65MhKTzUpfAQpyLCXFX/H+pSRKhL4aFO5XlK9cb8rQpxOvSvu/sqIsyla19ZqLJKn27s3UYXxDeRw+HQln1FWplToPW5HsUc/dr3TG2mltFuuZwOOR0OFZVVylNSoeIyr6LDQ9S8SZiaRoaZ3z9DhkKcToWFOLWnoEQffLdTS7cdNMfWplmkureJU9PIMMVGhCouMlSxEVW3H3YV6qNlO5VbeGzm6cKEJrq4dZzaNovU/qIyvbN4h0KcDr13e299t+2gJhyd4WkWFaaDxeXm8y5KiNY1F7dSQUmF1uwu1Nb9xYoOD1GLKLdaRIepRRO3mke51SwqVCEup1wOh5xOh0KcVf91ORxyOR1Hxy35DMlnGDIMw/x/hxwKcTkU6nIoxOlUiMuhDbmH9eTsdZKk3/+8veZs2Ku1ezxqFRuuh4d0VJQ7RKFOp3YXHNHWfcXaVVCihOhwndcySqnNo+RyOmQYhrzV73P0Z9Md6lREqEuhLufR73/V9z3U5ZQ7xKmt+4r1+Zpczd2wVyUVXrWPb6KuyXE6r2WUYsJD1CQ8RNHuqp+nKHeItuwr0nfbD2rFjgKFuBxKjAlXYuzRW0y4cgtLNeGrjfIZUtPIUB06GtivTUtSs8hQrcv1aE9BqTq2ilb3Nk3Vplmk1uV6tCqnQHsPlyq1eZTOj2+ilGaRinaHKDLMJXeoS8f/Ca/+e+44buvxf+Mdjqpr91V/D5wOh3nf4aiaeX36s/UyDKlt80jtOFDVPhzVK0XXpiUpItQlh8OhvMIS7TpUIk9JheJjwpUcF2H+oTZkyDCk6l9Bh3T0e+qUQzJ/1xwOKSzEKZfToa37irVs+0GtzCmQy+lQaotItWkWpWZRoYpyhygqrOprHBnmkjvEqZyDR7R5b5FyDh5RRKhLcdU/95FhiosI1fYDxXo5+0ftLyozx57WOlaj01NVUFKhnQePqLTCq7bNo3Reyyi5HA6ty/Vo3R6PKrw+nR/fRO1bNjF/T0OO/tyGuBxyOZ1yHvd1Nr/mjmNfd4fj2P1j35Pq70XVts9X52ri15v9PitbNAnTI0M6Vf0jKtSpSq+hvMJS5XpKVVHpU0JMuBJj3YoOD636Wh/3OWfo2J2ffv5Vj0GSth8o1vrcw9q2v1hN3CFKjA1XfLRbUe4QRYS6FBFW/TnnksMh5ReWandBiQqOVCgizKUot0uRYVXfk0i3S1v3FWvWyt3675b9Mgypc1KMhnZLUsdWMcr3lCnfUyqnw6GkuHC1io3QoSPl2ph3WJvyDysqLETnx0epfXwTtW8ZrTbNrQ1L9TrwlJeXKzIyUh9//LGGDRtmbh8zZowKCgr0ySef1HhOmzZtdN9992n8+PHmtscff1yzZs3S999/X2P/srIylZUd+yXxeDxKSUmpF4HnZPI9pVqf69EFCdFKig2v8a+cCq9Pb8zfoqx1+Vq7x2POAjWNDFXvds2V5ynV97sKavwSHc/ldOj/XXGe/jDwAhWXVerzNXlavPWApKrT5otKK7U855A5K/PrHq31zPVdFeJyanP+Yd0y9TvtLijxe83MW3tqwEXHZu0Mw/Cr3TAMvfj1Zr2UvblGPV2TY3X5BS20p6BEi7ceUL6nrMY+VvjjlRfqnqPLB0xbvF2PfbI2IO/zU06HdEF8tH7cV1SrZQeaRYWpZRO3NuYfPuHjTw3trJvTU2UYhp74dJ0yF22XJEWGudQ5KUY/7CpU2XEzcsFwW792evSajlXhd8q3+nFvUVDrOVP/c0lrPX19F03973a98OUG2fFY/N/0bqMnr+uszEXbzQBUH7VtHqkBF7bU9OW7zNlLuxnWLUk39WmrR2at0Ya8E/9+1hcup+OMl0FpH99EX9/X39J66nXg2bNnj5KTk7Vo0SKlp6eb2x988EHNnz9fS5YsqfGcsLAwvfPOOxo1apS57fXXX9cTTzyh/Pya/em//OUveuKJJ2psr8+Bpy6OlFdqzW6PotwudUyMMVszB4rKtHjrAR0p9x79l7tUVOaVp6RCpRVeXd2llTolnfrr4/MZ2ry3SAeKypR+fnO/8FJS7tXKnEPaXVCi3QUlSoqN0IgerWs1Bb0y55D2FJQq1OVQaIhTHRNjlBh7rP1mGIZyC0t1sLhcntIKHS6tmlHxlFaquKzS719woa6qWQVJKqvwqaTCq7IKr0qO3kqP29a2eZQeurqDQlxO831en7dFG/MOy2cY8hmGEmMidEnbOKW1jtPew6Vauu2QVuQcUnFZpby+qn2i3CGKCQ9VlNslT2mlDhSVqeBIhRyOqrocDqnCWzXzFOpy6pddEjWiR4oSY6tm4pZtP6RN+YdVWFKhgpIKFZZUqPBI1X+bRoXpV5e21uDOCXKHuHSwuFxLtx3Q5vwi7Th4RDsPHlH6+c01buAF5tfa5zP09fp8NYsKU1pKnEJdThWWVGj2D3v0zaZ9ahUboc5JMbowIVpHyr3aX1SmA0Vl2l9Urv1Ha688Ojav77ibYch3dDbNMAw5j85wOR1V605Vz/pUen2q9BnmmL0+Q4M7J+rBwReZP4/5nlJlfLZeOw+VqLTCq/JKnxJjw3Veiyi1bhqpPE+ptu4r0q5DJTKkGrMZ0tE1no4+t/r77lDV17qs0qfYiBAN6pSgqzonKjkuQqt3F+r7XYXKKyzR4dLKo7eqn6fDZZVKiHGrV2pz9UxtqhBX1SxgXmGJ8grLlOcpkaekUv9zSbLG9E01v9bfbj2gD5bmqGW0W52SYpQYE6F1uR6t2HFIuwpK1DExWmlH25Y7DhRry75i7Sko0ZFyr4rLK1VWcSyEGsf9vJ9I1axL1ffCMHR0xsuQzyfzexXqcmp0elvdecV5Zo1zNuRr0rwtKjhSodJKryq9hhJiwpXcNEJxEaHK95RpT0GJORtYNbMhv9/dCq/PnDkNcTrNFnuF16fySp8SYsPVM7WpLmnTVE6Hw/zZLCypUHFZpYrLK3WkrGrMJeVeJcVF6IKEaKU2j1R5pU8FR3/eC0rKzX9UjerVRqN6tVFYiFP7Dpdp0rwtWpFzSElx4UppFqnwEJe2HyjW1n3FqvD61KlVjDolxcgd4tSWfcXasq/I/Fn2+nzmz3GF1zC/xsZxX9fjZ7WqHj62zTAMv8cMw1B0eKju/cWF+tWlrc2fx5eyN+vLtXkqq/CprNIrp8NhzhCGupzK95Qqz1OqI+XeE87sHbfl+O+8OYvt9Rlq3TRCHVvFqH3LJjpS4VV+Yan2FZXpSHnVmmclFcf+6/UZSohxKykuQs2iwlRa4a362SurVPHR70cTd4iGdG2lod2SFR0eov+sztXsH/boQFG5EmPDlRATLp/P0O6CEuUWlqqJO0QdWkXroqOfHz/uK9KWvUW6KDFaL93Q/YQ/u2eKwKNTB56GOMMDAEBjc7aBJ6gLD7Zo0UIul6tGUMnPz1diYuIJn5OYmFin/d1ut9zu+nnQGAAAsEZQT0sPCwvTpZdequzsbHObz+dTdna234zP8dLT0/32l6SsrKyT7g8AABD0S0vcd999GjNmjHr06KFevXrpxRdfVHFxsW699VZJ0ujRo5WcnKyMjAxJ0rhx49S/f39NmDBBQ4YM0QcffKBly5ZpypQpwRwGAACwsaAHnpEjR2rfvn167LHHlJeXp27duumLL75QQkLVtaJycnLkdB6biOrbt6/ef/99PfLII/rf//1fXXDBBZo1a1at1uABAACNU9DX4TnX6tM6PAAAoMrZ/v22xaUlAAAAAonAAwAAGjwCDwAAaPAIPAAAoMEj8AAAgAaPwAMAABo8Ag8AAGjwCDwAAKDBI/AAAIAGL+iXljjXqheW9ng8Qa4EAADUVvXf7TO9QESjCzyHDx+WJKWkpAS5EgAAUFeHDx9WbGxsnZ/X6K6l5fP5tGfPHkVHR8vhcJz163k8HqWkpGjnzp0N+tpcjWWcEmNtiBrLOKXGM9bGMk6p8Yz1dOM0DEOHDx9WUlKS30XFa6vRzfA4nU61bt3a8teNiYlp0D+I1RrLOCXG2hA1lnFKjWesjWWcUuMZ66nGeSYzO9U4aBkAADR4BB4AANDgEXjOktvt1uOPPy632x3sUgKqsYxTYqwNUWMZp9R4xtpYxik1nrEGepyN7qBlAADQ+DDDAwAAGjwCDwAAaPAIPAAAoMEj8AAAgAaPwHMWXnvtNaWmpio8PFy9e/fW0qVLg13SWcvIyFDPnj0VHR2t+Ph4DRs2TBs3bvTbp7S0VGPHjlXz5s3VpEkT/c///I/y8/ODVLE1nn32WTkcDo0fP97c1pDGuXv3bt10001q3ry5IiIi1LVrVy1btsx83DAMPfbYY2rVqpUiIiI0aNAgbd68OYgV153X69Wjjz6qdu3aKSIiQueff76eeuopv+vu1NdxfvPNN7r22muVlJQkh8OhWbNm+T1em3EdPHhQN954o2JiYhQXF6ff/va3KioqOoejqJ1TjbWiokJ/+tOf1LVrV0VFRSkpKUmjR4/Wnj17/F6jPoz1dN/T4911111yOBx68cUX/bbXh3FKtRvr+vXrdd111yk2NlZRUVHq2bOncnJyzMet+Dwm8JyhDz/8UPfdd58ef/xxrVixQmlpaRo8eLD27t0b7NLOyvz58zV27Fh9++23ysrKUkVFha688koVFxeb+9x777369NNPNX36dM2fP1979uzR8OHDg1j12fnuu+/0xhtv6OKLL/bb3lDGeejQIfXr10+hoaH6/PPPtW7dOk2YMEFNmzY193n++ef18ssva/LkyVqyZImioqI0ePBglZaWBrHyunnuuec0adIkvfrqq1q/fr2ee+45Pf/883rllVfMferrOIuLi5WWlqbXXnvthI/XZlw33nij1q5dq6ysLM2ePVvffPON7rzzznM1hFo71ViPHDmiFStW6NFHH9WKFSs0Y8YMbdy4Udddd53ffvVhrKf7nlabOXOmvv32WyUlJdV4rD6MUzr9WLds2aLLLrtMHTp00Lx58/TDDz/o0UcfVXh4uLmPJZ/HBs5Ir169jLFjx5r3vV6vkZSUZGRkZASxKuvt3bvXkGTMnz/fMAzDKCgoMEJDQ43p06eb+6xfv96QZCxevDhYZZ6xw4cPGxdccIGRlZVl9O/f3xg3bpxhGA1rnH/605+Myy677KSP+3w+IzEx0XjhhRfMbQUFBYbb7Tb++c9/nosSLTFkyBDjtttu89s2fPhw48YbbzQMo+GMU5Ixc+ZM835txrVu3TpDkvHdd9+Z+3z++eeGw+Ewdu/efc5qr6ufjvVEli5dakgyduzYYRhG/Rzryca5a9cuIzk52VizZo3Rtm1bY+LEieZj9XGchnHisY4cOdK46aabTvocqz6PmeE5A+Xl5Vq+fLkGDRpkbnM6nRo0aJAWL14cxMqsV1hYKElq1qyZJGn58uWqqKjwG3uHDh3Upk2bejn2sWPHasiQIX7jkRrWOP/973+rR48eGjFihOLj49W9e3f9/e9/Nx/ftm2b8vLy/MYaGxur3r1716ux9u3bV9nZ2dq0aZMk6fvvv9fChQt19dVXS2o44/yp2oxr8eLFiouLU48ePcx9Bg0aJKfTqSVLlpzzmq1UWFgoh8OhuLg4SQ1nrD6fTzfffLMeeOABde7cucbjDWmc//nPf3ThhRdq8ODBio+PV+/evf3aXlZ9HhN4zsD+/fvl9XqVkJDgtz0hIUF5eXlBqsp6Pp9P48ePV79+/dSlSxdJUl5ensLCwswPl2r1cewffPCBVqxYoYyMjBqPNaRxbt26VZMmTdIFF1ygL7/8Unfffbf+8Ic/6J133pEkczz1/ef5z3/+s2644QZ16NBBoaGh6t69u8aPH68bb7xRUsMZ50/VZlx5eXmKj4/3ezwkJETNmjWr12MvLS3Vn/70J40aNcq82GRDGetzzz2nkJAQ/eEPfzjh4w1lnHv37lVRUZGeffZZXXXVVfrqq690/fXXa/jw4Zo/f74k6z6PG93V0lF7Y8eO1Zo1a7Rw4cJgl2K5nTt3aty4ccrKyvLrEzdEPp9PPXr00DPPPCNJ6t69u9asWaPJkydrzJgxQa7OOh999JH+8Y9/6P3331fnzp21atUqjR8/XklJSQ1qnKhSUVGhX//61zIMQ5MmTQp2OZZavny5XnrpJa1YsUIOhyPY5QSUz+eTJA0dOlT33nuvJKlbt25atGiRJk+erP79+1v2XszwnIEWLVrI5XLVOEI8Pz9fiYmJQarKWvfcc49mz56tuXPnqnXr1ub2xMRElZeXq6CgwG//+jb25cuXa+/evbrkkksUEhKikJAQzZ8/Xy+//LJCQkKUkJDQIMYpSa1atVKnTp38tnXs2NE8A6J6PPX95/mBBx4wZ3m6du2qm2++Wffee685g9dQxvlTtRlXYmJijRMqKisrdfDgwXo59uqws2PHDmVlZZmzO1LDGOuCBQu0d+9etWnTxvx82rFjh+6//36lpqZKahjjlKr+noaEhJz2M8qKz2MCzxkICwvTpZdequzsbHObz+dTdna20tPTg1jZ2TMMQ/fcc49mzpypOXPmqF27dn6PX3rppQoNDfUb+8aNG5WTk1Ovxj5w4ECtXr1aq1atMm89evTQjTfeaP5/QxinJPXr16/G0gKbNm1S27ZtJUnt2rVTYmKi31g9Ho+WLFlSr8Z65MgROZ3+H2kul8v8F2RDGedP1WZc6enpKigo0PLly8195syZI5/Pp969e5/zms9GddjZvHmzvv76azVv3tzv8YYw1ptvvlk//PCD3+dTUlKSHnjgAX355ZeSGsY4paq/pz179jzlZ5Rlf3fqeIA1jvrggw8Mt9ttZGZmGuvWrTPuvPNOIy4uzsjLywt2aWfl7rvvNmJjY4158+YZubm55u3IkSPmPnfddZfRpk0bY86cOcayZcuM9PR0Iz09PYhVW+P4s7QMo+GMc+nSpUZISIjx9NNPG5s3bzb+8Y9/GJGRkcZ7771n7vPss88acXFxxieffGL88MMPxtChQ4127doZJSUlQay8bsaMGWMkJycbs2fPNrZt22bMmDHDaNGihfHggw+a+9TXcR4+fNhYuXKlsXLlSkOS8be//c1YuXKleWZSbcZ11VVXGd27dzeWLFliLFy40LjggguMUaNGBWtIJ3WqsZaXlxvXXXed0bp1a2PVqlV+n1FlZWXma9SHsZ7ue/pTPz1LyzDqxzgN4/RjnTFjhhEaGmpMmTLF2Lx5s/HKK68YLpfLWLBggfkaVnweE3jOwiuvvGK0adPGCAsLM3r16mV8++23wS7prEk64W3q1KnmPiUlJcbvfvc7o2nTpkZkZKRx/fXXG7m5ucEr2iI/DTwNaZyffvqp0aVLF8PtdhsdOnQwpkyZ4ve4z+czHn30USMhIcFwu93GwIEDjY0bNwap2jPj8XiMcePGGW3atDHCw8ON8847z3j44Yf9/hDW13HOnTv3hL+XY8aMMQyjduM6cOCAMWrUKKNJkyZGTEyMceuttxqHDx8OwmhO7VRj3bZt20k/o+bOnWu+Rn0Y6+m+pz91osBTH8ZpGLUb61tvvWW0b9/eCA8PN9LS0oxZs2b5vYYVn8cOwzhuGVIAAIAGiGN4AABAg0fgAQAADR6BBwAANHgEHgAA0OAReAAAQINH4AEAAA0egQcAADR4BB4AANDgEXgABFVqaqpefPHFYJehRx99VHfeeWewyzitG264QRMmTAh2GUC9Q+ABGolbbrlFw4YNM+8PGDBA48ePP2fvn5mZqbi4uBrbv/vuu6AHjby8PL300kt6+OGHz/g1nn76afXt21eRkZEnHKck5eTkaMiQIYqMjFR8fLweeOABVVZW+u0zb948XXLJJXK73Wrfvr0yMzP9Hn/kkUf09NNPq7Cw8IxrBRojAg+As1JeXn5Wz2/ZsqUiIyMtqubMvPnmm+rbt695deZq//3vf1VRUVFj/3Xr1ik/P99vW3l5uUaMGKG77777hO/h9Xo1ZMgQlZeXa9GiRXrnnXeUmZmpxx57zNxn27ZtGjJkiH72s59p1apVGj9+vG6//XbzCtmS1KVLF51//vl67733zmbIQONz9pcFA1AfjBkzxhg6dKj5//rJhfy2bdtmGIZhrF692rjqqquMqKgoIz4+3rjpppuMffv2ma/Tv39/Y+zYsca4ceOM5s2bGwMGDDAMwzAmTJhgdOnSxYiMjDRat25t3H333eaFDE908cDHH3/cMIyaF0XcsWOHcd111xlRUVFGdHS0MWLECCMvL898/PHHHzfS0tKMadOmGW3btjViYmKMkSNHGh6Px9xn+vTpRpcuXYzw8HCjWbNmxsCBA42ioqKTfm06d+5svPrqq37bvF6vkZaWZvzqV78yKisrze0bNmwwEhISjOeee+6ErzV16lQjNja2xvbPPvvMcDqdfmOZNGmSERMTY17g9MEHHzQ6d+7s97yRI0cagwcP9tv2xBNPGJdddtlJxwOgJmZ4gEbopZdeUnp6uu644w7l5uYqNzdXKSkpKigo0M9//nN1795dy5Yt0xdffKH8/Hz9+te/9nv+O++8o7CwMP33v//V5MmTJUlOp1Mvv/yy1q5dq3feeUdz5szRgw8+KEnq27evXnzxRcXExJjv98c//rFGXT6fT0OHDtXBgwc1f/58ZWVlaevWrRo5cqTfflu2bNGsWbM0e/ZszZ49W/Pnz9ezzz4rScrNzdWoUaN02223af369Zo3b56GDx8u4yTXST548KDWrVunHj16+G13Op367LPPtHLlSo0ePVo+n09btmzRz3/+cw0bNswcW20tXrxYXbt2VUJCgrlt8ODB8ng8Wrt2rbnPoEGD/J43ePBgLV682G9br169tHTpUpWVldWpBqAxCwl2AQDOvdjYWIWFhSkyMlKJiYnm9ldffVXdu3fXM888Y257++23lZKSok2bNunCCy+UJF1wwQV6/vnn/V7z+OOBUlNT9de//lV33XWXXn/9dYWFhSk2NlYOh8Pv/X4qOztbq1ev1rZt25SSkiJJmjZtmjp37qzvvvtOPXv2lFQVjDIzMxUdHS1Juvnmm5Wdna2nn35aubm5qqys1PDhw80WVdeuXU/6njk5OTIMQ0lJSTUeS0pK0pw5c3T55ZfrN7/5jRlIJk2adNLXO5m8vDy/sCPJvJ+Xl3fKfTwej0pKShQREWHWVV5erry8vBptOAAnxgwPANP333+vuXPnqkmTJuatQ4cOkqpmVapdeumlNZ779ddfa+DAgUpOTlZ0dLRuvvlmHThwQEeOHKn1+69fv14pKSlm2JGkTp06KS4uTuvXrze3paammmFHklq1aqW9e/dKktLS0jRw4EB17dpVI0aM0N///ncdOnTopO9ZUlIiSQoPDz/h423atNG7776rDz/8UCEhIXrrrbfkcDhqPaZAqA4+dfnaAo0dgQeAqaioSNdee61WrVrld9u8ebOuuOIKc7+oqCi/523fvl3XXHONLr74Yv3rX//S8uXL9dprr0k6+4OaTyQ0NNTvvsPhkM/nkyS5XC5lZWXp888/V6dOnfTKK6/ooosu0rZt2074Wi1atJCkk4ai/Px83Xnnnbr22mt15MgR3XvvvWdUc2JiYo0DnavvV896nWyfmJgYM+RIVW04qeqAbwC1Q+ABGqmwsDB5vV6/bZdcconWrl2r1NRUtW/f3u/205BzvOXLl8vn82nChAnq06ePLrzwQu3Zs+e07/dTHTt21M6dO7Vz505z27p161RQUKBOnTrVemwOh0P9+vXTE088oZUrVyosLEwzZ8484b7nn3++YmJitG7duhqP7d+/XwMHDlTHjh01Y8YMZWdn68MPPzzh8Uenk56ertWrV5szUZKUlZWlmJgYc2zp6enKzs72e15WVpbS09P9tq1Zs0atW7c2wxqA0yPwAI1UamqqlixZou3bt2v//v3y+XwaO3asDh48qFGjRum7777Tli1b9OWXX+rWW289ZVhp3769Kioq9Morr2jr1q169913zYOZj3+/oqIiZWdna//+/SdsxwwaNEhdu3bVjTfeqBUrVmjp0qUaPXq0+vfvX+Og4pNZsmSJnnnmGS1btkw5OTmaMWOG9u3bp44dO55wf6fTqUGDBmnhwoV+230+n66++mq1bdvWbGd16tRJWVlZmjp1qiZOnOi3f05OjlatWqWcnBx5vV5zdqyoqEiSdOWVV6pTp066+eab9f333+vLL7/UI488orFjx8rtdkuS7rrrLm3dulUPPvigNmzYoNdff10fffRRjVmlBQsW6Morr6zV1wPAUcE+TQzAuXH8aemGYRgbN240+vTpY0RERPidlr5p0ybj+uuvN+Li4oyIiAijQ4cOxvjx4w2fz2cYRtVp6ePGjavx+n/729+MVq1aGREREcbgwYONadOmGZKMQ4cOmfvcddddRvPmzS05Lf14EydONNq2bWsYhmGsW7fOGDx4sNGyZUvD7XYbF154ofHKK6+c8mvz2WefGcnJyYbX6/Xb/tVXXxklJSU19l+xYoWxc+dOv20nOtVfkjF37lxzn+3btxtXX321ERERYbRo0cK4//77jYqKCr/XmTt3rtGtWzcjLCzMOO+884ypU6f6PV5SUmLExsYaixcvPuWYAPhzGMZJztUEgEbCMAz17t1b9957r0aNGhXsck5p0qRJmjlzpr766qtglwLUK7S0ADR6DodDU6ZMqXGZBzsKDQ3VK6+8EuwygHqHGR4AANDgMcMDAAAaPAIPAABo8Ag8AACgwSPwAACABo/AAwAAGjwCDwAAaPAIPAAAoMEj8AAAgAaPwAMAABq8/w+jAVFpeoBN9QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './kdd99/'\n",
    "timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d_%H%M%S_')\n",
    "old_model_name = ''\n",
    "new_model_name = timestamp + 'resnet_model.pth'\n",
    "\n",
    "if old_model_name != '':\n",
    "    resnet_model.load_state_dict(torch.load(old_model_name))\n",
    "else:\n",
    "    losses, iter = train(resnet_model, optimizer, loss_fn, epochs)\n",
    "    torch.save(resnet_model.state_dict(), path + new_model_name)\n",
    "\n",
    "    loss_value_plot(losses, iter)\n",
    "    plt.savefig(path + timestamp + 'resnet_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9992308003724546\n",
      "Average Loss: 0.004080249528269256\n"
     ]
    }
   ],
   "source": [
    "test(resnet_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
